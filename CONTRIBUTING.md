# Contributing to the Agent Governance Scorecard

Thank you for your interest in improving the Agent Governance Scorecard. This framework is intended to serve the entire AI industry, and community input makes it stronger.

## Ways to Contribute

### 1. Suggest New Criteria

If you believe an important governance dimension is missing:

1. Open an issue with the title: `[Criteria Suggestion] Your Criterion Name`
2. Include:
   - The criterion name
   - Which dimension it belongs to (or propose a new dimension)
   - Why it matters for enterprise governance
   - How it would be evaluated (Yes/Partial/No)
   - Example evidence that would satisfy it

### 2. Report Ambiguities

If a criterion is unclear or could be interpreted multiple ways:

1. Open an issue with the title: `[Clarification] Criterion Name`
2. Explain the ambiguity
3. Suggest clearer language if possible

### 3. Share Anonymized Assessments

Assessments of real platforms (anonymized) help establish industry benchmarks:

1. Complete the scorecard for a platform
2. Anonymize: Remove vendor names, replace with "Vendor A", "Vendor B", etc.
3. Submit as PR to `assessments/`
4. Include brief context (industry, scale, use case)

### 4. Translations

Help make this scorecard accessible globally:

1. Fork the repository
2. Create `translations/[language-code]/`
3. Translate README.md and SCORECARD.md
4. Submit PR with your translation

### 5. Tooling

If you build tools around the scorecard (validators, assessment apps, etc.):

1. Open an issue to discuss before building
2. Tools should be MIT licensed
3. Submit as PR to `tools/` directory

## Guidelines

### For Criteria Suggestions

- **Must be verifiable** — Can be assessed with Yes/Partial/No
- **Must be architectural** — Not policy or process based
- **Must be vendor-neutral** — Applicable to any platform
- **Should have evidence standard** — What proves compliance?

### For All Contributions

- Be respectful and constructive
- Focus on improving governance outcomes
- Avoid vendor-specific language
- Remember the evidence standard: Roadmaps don't count

## Review Process

1. All contributions are reviewed by maintainers
2. Criteria changes require discussion in issues before PR
3. Major changes will be batched into version releases
4. Contributors will be credited in release notes

## Code of Conduct

- Be respectful of differing viewpoints
- Accept constructive criticism gracefully
- Focus on what's best for the community
- Show empathy towards others

## Questions?

- Open an issue for public discussion
- Email scorecard@equilateral.ai for private matters

---

Thank you for helping improve AI agent governance across the industry.
