# Attribution

The Agent Governance Scorecard is developed and maintained by
[Equilateral AI](https://equilateral.ai).

## How to Cite

When using or referencing this scorecard, please include attribution.

### Full Citation

```
Agent Governance Scorecard v1.0, Equilateral AI, 2026.
https://github.com/Equilateral-AI/agent-governance-scorecard
```

### Short Citation

```
Based on the Agent Governance Scorecard by Equilateral AI
```

### Academic Citation (BibTeX)

```bibtex
@misc{agent-governance-scorecard,
  title = {Agent Governance Scorecard},
  author = {Equilateral AI},
  year = {2026},
  version = {1.0},
  url = {https://github.com/Equilateral-AI/agent-governance-scorecard},
  note = {A framework for evaluating AI agent governance readiness}
}
```

## Framework Attribution

This scorecard operationalizes governance principles based on the published research and public statements of **Tracy Bannon**, Senior Principal Software Architect and Researcher at MITRE Corporation, where she leads the ArchAITecture initiative and AI research collaborations (A²RC).

> **Note:** This interpretation was compiled by Equilateral AI from publicly available sources. It is not written or endorsed by Tracy Bannon or MITRE. See [FRAMEWORK.md](FRAMEWORK.md) for details.

### The Bannon Vision

Tracy Bannon envisions an "agentic future" where AI systems evolve from
tools to teammates — active participants in software development. But she
emphasizes that this future requires governance infrastructure:

> "AI should be treated not as magic, but as software and data — meaning
> it must be governed by proper software architecture and engineering
> practices, not guesswork."

> "Organizations must establish 'control towers' for AI — treating agents
> as organizational resources that need management and accountability,
> rather than as uncontrolled experiments."

> "Traceability over blind trust."

### The Three Pillars

Bannon identifies three critical governance factors for managing AI agents
at enterprise scale:

1. **Interoperability** — Avoid vendor lock-in; ensure agents work across
   different tools and platforms
2. **Observability** — Complete visibility into agent actions and decisions
   (monitorable, auditable)
3. **Governance** — Strict controls over data access and permissions;
   enforced policies

### Calibrated Trust

Bannon advocates for "calibrated trust" — knowing when to trust AI output
and when to intervene:

> "We don't just need people who use AI. We need people who design for AI
> and with AI."

This includes human/machine teaming, checkpoints for human review, automated
validation pipelines, and AI fluency training.

### The Infrastructure Imperative

Bannon notes that the agentic future "isn't coming — it's already here,"
with organizations running thousands of AI agents in production. But:

> "Realizing this future at scale will require more than just sophisticated
> AI models; it demands new infrastructure, frameworks, and cultural shifts."

This scorecard is part of that infrastructure.

### Sources

- [Tracy Bannon on LinkedIn](https://www.linkedin.com/in/tracylbannon/)
- [Research on the Human/Machine Frontier](https://devops.com/research-on-the-human-machine-frontier-unleashing-generative-ai-in-software-engineering/) — DevOps.com, September 2024
- [MITRE ArchAITecture Initiative](https://www.mitre.org/)
- All Day DevOps 2024 — AI in SDLC presentation
- Joao Moura insights shared by Bannon — "The agentic future is already here"

## Using the Scorecard

You are free to use this scorecard for:

- Evaluating AI agent platforms (vendors or internal)
- Self-assessment of your own platform
- RFP and procurement criteria
- Research and analysis
- Training and education
- Commercial purposes

Under CC BY 4.0, the only requirement is attribution.

## Questions About Attribution?

Contact: scorecard@equilateral.ai
